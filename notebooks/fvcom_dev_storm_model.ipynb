{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1afcd6a9-407c-42c4-a78d-d02fbbc2f2bc",
   "metadata": {},
   "source": [
    "# Development processes for creating storm meteorological field for FVCOM\n",
    "**Author: Jun Sasaki  Coded on November 6, 2021  Updated on January 1, 2022**<br>\n",
    "- Creating a meteorological forcing file for FVCOM 4.4.2 with NetCDF-4.\n",
    "- NetCDF-4 on ITO-A is available.\n",
    "- Referred to [Honda & Sameshima (2018](https://www.ysk.nilim.go.jp/kenkyuseika/pdf/ks1039.pdf), [Tajima et al. (2016)](https://doi.org/10.1142/S0578563416400027), and [Liu and Sasaki (2019)](https://doi.org/10.1038/s41598-019-48728-7)\n",
    "- For storm data, [besttracks](https://github.com/jsasaki-utokyo/besttracks) is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb99303c-8163-4db3-8abb-12b77ff83e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from PyFVCOM.read import ncread  ## too slow\n",
    "import PyFVCOM as pf\n",
    "import netCDF4\n",
    "from cftime import num2date, date2num\n",
    "import cftime\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from dateutil.parser import parse\n",
    "import sys\n",
    "import os\n",
    "from pyproj import Proj\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "plt.rcParams['font.size'] =16\n",
    "## Using besttracks\n",
    "from besttracks import parseJMA\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23200e45-0a53-4677-9173-c0e6329b8eb4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Read FVCOM grid and set up coordinate variables\n",
    "### Set FVCOM grid file (`True`) or output netCDF (`False`) and Casename_wnd.nc\n",
    "- When **fvcom_grid** is read for the first time, it is serialized to **fvcom_grid_pickle**, which is to be deserialized quickly next time.\n",
    "- `x[node], y[node], lon[node], lat[node], xc[nele], yc[nele], lonc[nele], latc[nele] nv[three, nele]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb8743f-c557-48f7-817a-42484172171c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select FVCOM grid file (True) or output netCDF (False)\n",
    "grid_is_fvcom = True\n",
    "fvcom_nc = \"tokyobay_futtsu1.0_0001.nc\" ## optional\n",
    "casename = \"tb_futtsu\"\n",
    "fvcom_grid = casename + \"_grd.dat\"\n",
    "fvcom_grid_pickle = casename + \"_grd.pickle\"\n",
    "fvcom_wnd  = casename + \"_wnd.nc\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57caf11-3720-4eb8-b91d-5e7f53d644ac",
   "metadata": {},
   "source": [
    "### from FVCOM output netCDF\n",
    "- `netCDF.Datase(fvcom_nc, 'r')`\n",
    "- This is fast but needs FVCOM output netCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86cddd9-336d-4b87-97d7-157f921bb30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not grid_is_fvcom:\n",
    "    ## Reading grids from FVCOM output netCDF, which is fast.\n",
    "    print(\"Reading the FVCOM grid from FVCOM output netCDF\")\n",
    "    FVCOM = netCDF4.Dataset(fvcom_nc, 'r')\n",
    "    ## FVCOM = ncread(fvcom_nc)  ## too slow\n",
    "    x=FVCOM.variables['x'][:]   ## nodes\n",
    "    y=FVCOM.variables['y'][:]\n",
    "    xc=FVCOM.variables['xc'][:] ## elements\n",
    "    yc=FVCOM.variables['yc'][:]\n",
    "    nv = FVCOM.variables['nv'][:].T - 1  ## tri elemnents; offset for Python indexing.\n",
    "    node = np.arange(1, x.size+1)\n",
    "    nele = np.arange(1, xc.size+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449b36d2-a5d6-44d4-bd74-57c574c5e441",
   "metadata": {
    "tags": []
   },
   "source": [
    "### from FVCOM grid file (or serialized pickle file)\n",
    "- `PyFVCOM.grid.Domain('hoge_grd.dat', 'cartesian', zone)` where zone is UTM zone number, e.g. '54'.\n",
    "- `mesh = PyFVCOM.grid.Domain('tokyobay_futtsu5.0_grd.dat', 'cartesian', '54')`\n",
    "- Grid data `mesh.grid.` lon, lat, lonc, latc, x, y, xc, yc, nv, open_boundaries, open_boundary_nodes\n",
    "- Grid dimensions `mesh.dims.` node, nele, element, open_boundary, open_boundary_nodes, elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c58b7f0-be9b-4cb1-a64b-c405d5fec8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_is_fvcom:\n",
    "    if os.path.isfile(fvcom_grid_pickle):\n",
    "        ## If serialized file exists, it is to be opened.\n",
    "        with open(fvcom_grid_pickle, \"rb\") as file:\n",
    "            mesh = pickle.load(file)\n",
    "            print(\"Reading the FVCOM grid from pickle. Ensure the serialized grid data is up-to-date.\")\n",
    "    else:\n",
    "        ## First time, read fvcom_grid and serialized it into fvcom_grid_pickle.\n",
    "        ## A bit slow; be patient.\n",
    "        #pickle_file = fvcom_grid[:-3] + \"pickle\"\n",
    "        print(\"Reading the FVCOM grid from\", fvcom_grid, \"and dumping into\", fvcom_grid_pickle, \"for efficiency.\" )\n",
    "        mesh = pf.grid.Domain(fvcom_grid, 'cartesian', '54')\n",
    "        with open(fvcom_grid_pickle, \"wb\") as file:\n",
    "            pickle.dump(mesh, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5056111-3d44-4670-8e18-cd30371b527a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_is_fvcom:\n",
    "    x = mesh.grid.x\n",
    "    y = mesh.grid.y\n",
    "    xc = mesh.grid.xc\n",
    "    yc = mesh.grid.yc\n",
    "    nv = mesh.grid.triangles\n",
    "    node = mesh.dims.node\n",
    "    nele = mesh.dims.nele"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a417d5f-0a5f-4254-bd97-051d88b8c027",
   "metadata": {},
   "source": [
    "## Converting between UTM and geographic coordinates using [Proj](https://pyproj4.github.io/pyproj/stable/api/proj.html)\n",
    "- `p=Proj(proj='utm', zone=54, ellps='WGS84')`\n",
    "- `lons, lats = p(xs, ys, inverse=True)`\n",
    "- `xs, ys = p(lons, lats)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad61a7d8-8ac4-4e6e-9124-74fa9dce97ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "zone = 54\n",
    "hemi='N'\n",
    "if hemi == 'S':\n",
    "    y  = y  - 10000000\n",
    "    yc = yc - 10000000\n",
    "## Define coordinate converter p\n",
    "p = Proj(proj='utm', zone=zone, ellps='WGS84')\n",
    "lon, lat = p(x, y, inverse=True)\n",
    "lonc, latc = p(xc, yc, inverse=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f311a148-d15e-42bd-9f61-2d2c67f571cf",
   "metadata": {},
   "source": [
    "## Create besttrack data using [besttracks](https://github.com/jsasaki-utokyo/besttracks)\n",
    "Set typhoon ID in YYYYNN where NN is the typhoon number in the year of YYYY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7218cd-adab-40ef-9139-477016edc602",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"/home/teem/Github/besttracks/data/jma_rsmc/bst_all.txt\"  ## Specify JMA best track data path\n",
    "ID = '201919'  ## Set typhoon ID\n",
    "df = parseJMA(fpath)\n",
    "# print(df.head())\n",
    "df = df[df.ID == ID]\n",
    "df = df.set_index('TIME')\n",
    "# df = df.tz_localize('UTC')  ## Set time zone as UTC\n",
    "df = df.resample('H').interpolate()  ## Up-sampling in every hour with interpolation \n",
    "XUTM, YUTM = p(df.LON.values, df.LAT.values, inverse=False)  ## convert to UTM using Proj()\n",
    "df['XUTM'] = XUTM\n",
    "df['YUTM'] = YUTM\n",
    "#print(df.PRS.values[240])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb587bf-5882-4fc2-9ca6-3e56e863a7f9",
   "metadata": {},
   "source": [
    "### Calculate translation speed\n",
    "The last row is a copy of the previous row so that the number of rows does not change. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bec02e-562c-4f13-871e-2f5b921e039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSLATION = np.sqrt(np.square(XUTM[1:]-XUTM[:-1]) + np.square(YUTM[1:]-YUTM[:-1])) / 3600\n",
    "TRANSLATION = np.append(TRANSLATION, TRANSLATION[-1])  ## Append the last row\n",
    "df['TRANSLATION'] = TRANSLATION\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "# print(df.TRANSLATION.values[10])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792b208e-d362-40ec-945c-4f8daa6566d0",
   "metadata": {},
   "source": [
    "### Extract best track parameters for parametric typhoon model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b37106-fcdf-466d-b357-e3b20526b8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt_c = df.XUTM.values  ## typhoon track center x in UTM\n",
    "yt_c = df.YUTM.values  ## typhoon track center y in UTM\n",
    "sp_c  = df.PRS.values   ## typhoon track central surface pressure in hPa\n",
    "translation_speed = df.TRANSLATION.values\n",
    "num_tracks = xt_c.size - 1 ## should be -1 to obtain typhoon translation vector (one more track required)\n",
    "timestamps = df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7341ba86-b0d1-4f8d-8190-3bfe25171d4b",
   "metadata": {},
   "source": [
    "## Prepare time variable consistent with that in FVCOM\n",
    "FVCOM uses modified julian day of \"days since 1858-11-17 00:00:00\" but calendar should be gregorian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1661eb-a7d7-4df9-96ec-69cc6ca05594",
   "metadata": {},
   "outputs": [],
   "source": [
    "def days_since_calendar_date(timestamp, calendar_date='1858-11-17 00:00:00'):\n",
    "    '''\n",
    "    Calculate days in real since calendar_date in UTM.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    timestamp: pandas Timestamp\n",
    "    calendar_date: str\n",
    "        Default modified julian day in FVCOM\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    days: real\n",
    "    '''\n",
    "    calendar_date = parse(calendar_date)\n",
    "    #print('calendar_date = ', calendar_date)\n",
    "    days_int = (timestamp - calendar_date).days\n",
    "    within_day = ((timestamp - calendar_date).seconds / (24*3600))\n",
    "    days = days_int + within_day\n",
    "    return days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04565ff9-991f-4d4a-a38d-41985c4f40a3",
   "metadata": {},
   "source": [
    "## Storm model netCDF definition\n",
    "- Use **NETCDF4** (default). The following is only for reference.\n",
    "- In the case of very huge data, NETCDF3_64BIT_OFFSET would not work by raising a strange error. NETCDF4_CLASSIC works.\n",
    "- FVCOM with netCDF-3.6.3 may need NETCDF3_64BIT_OFFSET.\n",
    "- Options: NETCDF4 (default), NETCDF4_CLASSIC (use the version 4 disk format (HDF) but omits features not found in the verion 3 API), NETCDF3_64BIT_OFFSET (introduced in version 3.6.0, allowing file sizes greater than 2GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5aee3fe-a9b0-4352-8866-b5828487054b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def netcdf_storm(ncfile, x, y, lon, lat, xc, yc, lonc, latc, nv, format=\"NETCDF4\",\n",
    "                 title = \"FVCOM storm forcing file\",\n",
    "                 institution = \"The University of Tokyo\",\n",
    "                 source = \"FVCOM grid (unstructured) surface forcing\",\n",
    "                 references = \"http://fvcom.smast.umassd.edu, http://codfish.smast.umassd.edu\",\n",
    "                 Conventions = \"CF-1.0\",\n",
    "                 units = \"days since 1858-11-17 00:00:00\", ## Modified Julian Day\n",
    "                 CoordinateSystem = \"Cartesian\",\n",
    "                 CoordinateProjection = \"init=epsg:32654\"):\n",
    "    '''\n",
    "    Create and define netCDF for storm model contining wind velocity and surface pressure.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ncfile(str): netCDF file name\n",
    "    x(ndarray): 1D real FVCOM node\n",
    "    y(ndarray): 1D real FVCOM node\n",
    "    lon(ndarray): 1D real FVCOM node\n",
    "    lat(ndarray): 1D real FVCOM node\n",
    "    xc(ndarray): 1D real FVCOM nele\n",
    "    yc(ndarray): 1D real FVCOM nele\n",
    "    lonc(ndarray): 1D real FVCOM nele (cell center)\n",
    "    latc(ndarray): 1D real FVCOM nele (cell center)\n",
    "    nv(ndarray): 2D int FVCOM nv(three, nele)\n",
    "    global_atts(dict): dictionary for global attributes\n",
    "    format(str): netCDF format: NETCDF3_64BIT_OFFSET(default), NETCDF4_CLASSIC, NETCDF4\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    netCDF4.Dataset\n",
    "    '''\n",
    "\n",
    "    nc = netCDF4.Dataset(ncfile, \"w\", format=format)  ## Sometimes does not work with large data.\n",
    "    # nc.set_fill_off()\n",
    "    time = nc.createDimension(\"time\", None)\n",
    "    node = nc.createDimension(\"node\", len(lat))\n",
    "    nele  = nc.createDimension(\"nele\", len(latc))\n",
    "    three = nc.createDimension(\"three\", 3)\n",
    "\n",
    "    ## Coordinate variables\n",
    "    times = nc.createVariable(\"time\", \"f8\", (\"time\",))  ## f8 required; f4 causing inaccurate time\n",
    "    nodes = nc.createVariable(\"node\", \"i4\", (\"node\",))\n",
    "    neles = nc.createVariable(\"nele\", \"i4\", (\"nele\",))\n",
    "    ## Variables\n",
    "    xs = nc.createVariable(\"x\", \"f4\", (\"node\",))\n",
    "    ys = nc.createVariable(\"y\", \"f4\", (\"node\",))\n",
    "    lons = nc.createVariable(\"lon\", \"f4\", (\"node\",))\n",
    "    lats = nc.createVariable(\"lat\", \"f4\", (\"node\",))\n",
    "    xsc = nc.createVariable(\"xc\", \"f4\", (\"nele\",))\n",
    "    ysc = nc.createVariable(\"yc\", \"f4\", (\"nele\",))\n",
    "    lonsc = nc.createVariable(\"lonc\", \"f4\", (\"nele\",))\n",
    "    latsc = nc.createVariable(\"latc\", \"f4\", (\"nele\",))\n",
    "    nvs = nc.createVariable(\"nv\", \"i4\", (\"nele\", \"three\",))\n",
    "\n",
    "    sp = nc.createVariable(\"air_pressure\", \"f4\", (\"time\", \"node\",))\n",
    "    u_w_x  = nc.createVariable(\"u_w_x\",  \"f4\", (\"time\", \"nele\",))\n",
    "    u_w_y  = nc.createVariable(\"u_w_y\",  \"f4\", (\"time\", \"nele\",))\n",
    "    ## Global attributes\n",
    "    nc.title = title\n",
    "    nc.institution = institution\n",
    "    nc.source = source\n",
    "    nc.history = \"created \" + datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    nc.references = references\n",
    "    nc.Conventions = Conventions\n",
    "    nc.CoordinateSystem = CoordinateSystem\n",
    "    nc.CoordinateProjection = CoordinateProjection\n",
    "    ## Coordinate variable attributes\n",
    "    times.units = \"days since 1858-11-17 00:00:00\" ## Modified Julian Day\n",
    "    times.calendar = \"standard\"\n",
    "    ## Variable attributes\n",
    "    xs.long_name = \"nodal x-coordinate\"\n",
    "    xs.units = \"meters\"\n",
    "    ys.long_name = \"nodal y-coordinate\"\n",
    "    ys.units = \"meters\"\n",
    "    lons.long_name = \"nodal longitude\"\n",
    "    lons.standard_name = \"longitude\"\n",
    "    lons.units = \"degrees_east\"\n",
    "    lats.long_name = \"nodal latitude\"\n",
    "    lats.standard_name = \"latitude\"\n",
    "    lats.units = \"degrees_north\"\n",
    "    xsc.long_name = \"zonal x-coordinate\"\n",
    "    xsc.units = \"meters\"\n",
    "    ysc.long_name = \"zonal y-coordinae\"\n",
    "    ysc.units = \"meters\"\n",
    "    lonsc.long_name = \"zonal longitude\"\n",
    "    lonsc.standard_name = \"longitude\"\n",
    "    lonsc.units = \"degrees_east\"\n",
    "    latsc.long_name = \"zonal latitude\"\n",
    "    latsc.standard_name = \"latitude\"\n",
    "    latsc.units = \"degrees_north\"\n",
    "    nvs.long_name = \"nodes surrounding element\"\n",
    "    sp.units = \"hPa\"\n",
    "    sp.long_name = \"surface air pressure\"\n",
    "    u_w_x.units = \"m/s\"\n",
    "    u_w_x.long_name = \"x component of wind velocity\"\n",
    "    u_w_y.units = \"m/s\"\n",
    "    u_w_y.long_name = \"y component of wind velocity\"\n",
    "    ## Writing coordinate variable data\n",
    "    #print(lat)\n",
    "    xs[:] = x\n",
    "    ys[:] = y\n",
    "    lats[:] = lat\n",
    "    lons[:] = lon\n",
    "    xsc[:] = xc\n",
    "    ysc[:] = yc\n",
    "    latsc[:] = latc\n",
    "    lonsc[:] = lonc\n",
    "    nvs[:,:] = nv\n",
    "\n",
    "    return nc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9c3a54-eac1-44fd-952b-d881daacf306",
   "metadata": {},
   "source": [
    "# Create parametric model netCDF\n",
    "### Add netCDF definitions for cyclonic and translation velocities in parametric model\n",
    "These are not defined in ERA and Hybrid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f39dae-bdd5-4677-ac17-e1fa260e9a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "nv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10067c6-3d0c-4f5f-8890-96b770c072ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = netcdf_storm('parametric_model.nc', x, y, lon, lat, xc, yc, lonc, latc, nv)\n",
    "u_w1_x = nc.createVariable(\"u_w1_x\", \"f4\", (\"time\", \"nele\",))\n",
    "u_w1_y = nc.createVariable(\"u_w1_y\", \"f4\", (\"time\", \"nele\",))\n",
    "u_w2_x = nc.createVariable(\"u_w2_x\", \"f4\", (\"time\", \"nele\",))\n",
    "u_w2_y = nc.createVariable(\"u_w2_y\", \"f4\", (\"time\", \"nele\",))\n",
    "u_w1_x.units = \"m/s\"\n",
    "u_w1_x.long_name = \"x component of cyclonic wind velocity\"\n",
    "u_w1_y.units = \"m/s\"\n",
    "u_w1_y.long_name = \"y component of cyclonic wind velocity\"\n",
    "u_w2_x.units = \"m/s\"\n",
    "u_w2_x.long_name = \"x component of translation velocity\"\n",
    "u_w2_y.units = \"m/s\"\n",
    "u_w2_y.long_name = \"y component of translation velocity\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0234f1b9-5df1-4bf7-a803-9d28e390d846",
   "metadata": {},
   "source": [
    "## Surface pressure of Myers model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca37961-f7b5-4597-81b0-1667ba07b763",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_0 = 1013.25  # ambient or environmental pressure in hPa\n",
    "r_min = 10\n",
    "r_max = (1.633 * sp_c - 1471.35) * 1000  ## when sp_c >= 950 hPa\n",
    "r_max_tmp = (0.769 * sp_c - 650.55) * 1000  ## when 880 hPa <= sp_c < 950 hPa\n",
    "index_sp_c_lt_950, = np.where(sp_c < 950)  ## array index where sp_c < 950 hPa \n",
    "r_max[index_sp_c_lt_950] = r_max_tmp[index_sp_c_lt_950]\n",
    "index_sp_c_lt_880, = np.where(sp_c < 880)\n",
    "#index_sp_c_lt_880.size\n",
    "if index_sp_c_lt_880.size > 0:\n",
    "    formatted = f\"WARNING: sp_c at indices of {index_sp_c_lt_880} < 880 hPa\"\n",
    "    print(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38df812d-6e01-40cb-9669-bc432283ae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "## sp: atm pressure at each node at i_track\n",
    "for i_track in np.arange(num_tracks):  ## loop for tracks\n",
    "    r = np.sqrt(np.square(x - xt_c[i_track].item()) + np.square(y - yt_c[i_track].item()))\n",
    "    sp = np.where(r > r_min, (sp_c[i_track]+(P_0-sp_c[i_track]) * np.exp(-r_max[i_track]/r)), sp_c[i_track])\n",
    "    nc.variables[\"air_pressure\"][i_track, :] = sp\n",
    "    nc.variables[\"time\"][i_track] = days_since_calendar_date(timestamps[i_track])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bedf52-822c-429e-9c3c-76f9feb76f01",
   "metadata": {},
   "source": [
    "## Wind field of Mitsuta-Fujii's model (1987)\n",
    "- Referred to [Tajima et al. (2016)](https://doi.org/10.1142/S0578563416400027)\n",
    "- `x_c`, `y_c` (`latc`): at elements.\n",
    "- `xt_c` and `yt_c`: at typhoon track center\n",
    "- Conversion from hPa to Pa is required by multiplying 100.\n",
    "\n",
    "$$\\boldsymbol{U_{\\text{w}}(r, \\theta)} = \\boldsymbol{U_{\\text{w1}}(r, \\theta)} + \\boldsymbol{U_{\\text{w2}}(r, \\theta)}$$\n",
    "$$U_{\\text{w1}}(r) = C_1 \\left( -\\frac{f_c r}{2} + \\sqrt{\\left( \\frac{f_c r}{2} \\right)^2 + \\frac{r}{\\rho_a} \\frac{\\partial P_a}{\\partial r}} \\right)$$\n",
    "$$P_a(r) = P_c + (P_0 - P_c) \\exp\\left(-\\frac{r_{\\text{max}}}{r} \\right) $$\n",
    "$$\\frac{\\partial P_a}{\\partial r} = (P_0 - P_c) \\frac{r_{\\text{max}}}{r^2} \\exp\\left( -\\frac{r_{\\text{max}}}{r} \\right)$$\n",
    "$$\\left. \\frac{\\partial P_a}{\\partial r}\\right |_{r=r_{\\text{max}}} = (P_0 - P_c)e^{-1}/r_{\\text{max}}$$\n",
    "$$\\boldsymbol{U_{\\text{w2}}(r, \\theta)} = C_2 \\frac{U_{\\text{w1}}(r)}{U_{\\text{w1}}(r_{\\text{max}})}\\boldsymbol{V_T}$$ \n",
    "\n",
    "where $\\boldsymbol{V_T}$ is the translation vector, $f_c$ is the Coriolis parameter. Suppose $u_{\\text{w1x}}$ and $u_{\\text{w1y}}$ are the tangential $x$ and $y$ components of $U_{\\text{w1}}(r)$,  $u_{\\text{w1x}} = -(y_{\\text{c}}-y_{\\text{tc}})/r \\times U_{\\text{w1}}(r)$ and $u_{\\text{w1y}} = (x_{\\text{c}}-x_{\\text{tc}})/r \\times U_{\\text{w1}}(r)$. Further, the velocity deflected with $\\alpha$ anticlockwise:\n",
    "$$ u_{\\text{w1x}} \\cos \\alpha - u_{\\text{w1y}} \\sin \\alpha$$ for x direction and $$u_{\\text{w1x}} \\sin \\alpha + u_{\\text{w1y}} \\cos \\alpha$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63e244c-d805-4d3e-b2f2-f18d9170ffa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "C1=2/3\n",
    "C2=2/3\n",
    "rho_a=1.225\n",
    "omega = 2 * np.pi/(24*3600) ## angular frequency of earth rotation\n",
    "alpha = 30 ## anticlockwise angle in dgree from the tangential direction of wind\n",
    "\n",
    "alpha = np.pi*alpha/180  ## degree -> radian\n",
    "for i_track in np.arange(num_tracks):  ## loop for typhoon tracks\n",
    "    r = np.sqrt(np.square(xc - xt_c[i_track]) + np.square(yc - yt_c[i_track]))\n",
    "    r = np.where(r >= r_min, r, r_min)  ## check: originally np.where(r >= r_min, r-r_min, r_min) but r-r_min may be zero. \n",
    "    f_c = 2 * omega * np.sin(np.pi*latc/180)\n",
    "    dpa_dr = (P_0 - sp_c[i_track]) * 100 * r_max[i_track]/np.square(r) * np.exp(-r_max[i_track]/r)\n",
    "    u_w1 = C1 * (-f_c*r/2 + np.sqrt(np.square(f_c*r/2) + r/rho_a * dpa_dr))\n",
    "    u_gr = C1 * (-f_c*r/2 + np.sqrt(np.square(f_c*r/2) + 100 * (P_0 - sp_c[i_track])*r_max[i_track]/(rho_a*r) * np.exp(-r_max[i_track]/r) ))\n",
    "    dpa_dr_r_max = (P_0 - sp_c[i_track]) * 100 * np.exp(-1)/r_max[i_track]  ## multply 100 to convert from hPa to Pa\n",
    "    ## tangential direction\n",
    "    u_w1_x_tmp = -(yc - yt_c[i_track])/r * u_w1  # x-component\n",
    "    u_w1_y_tmp =  (xc - xt_c[i_track])/r * u_w1  # y-component\n",
    "    ## rotating 30 degrees anticlockwise from the tangential direction\n",
    "    u_w1_x = u_w1_x_tmp * np.cos(alpha) - u_w1_y_tmp * np.sin(alpha)\n",
    "    u_w1_y = u_w1_x_tmp * np.sin(alpha) + u_w1_y_tmp * np.cos(alpha)\n",
    "    \n",
    "    u_w1_r_max = C1*(-f_c*r_max[i_track]/2 + np.sqrt(np.square(f_c*r_max[i_track]/2) + r_max[i_track]/rho_a * dpa_dr_r_max))\n",
    "    u_w2 = C2 * u_w1/u_w1_r_max * translation_speed[i_track]\n",
    "    \n",
    "    dr_t = np.sqrt(np.square(xt_c[i_track+1]-xt_c[i_track]) + np.square(yt_c[i_track+1]-yt_c[i_track]))\n",
    "    u_w2_x = (xt_c[i_track+1] - xt_c[i_track])/dr_t * u_w2\n",
    "    u_w2_y = (yt_c[i_track+1] - yt_c[i_track])/dr_t * u_w2\n",
    "    \n",
    "    u_w_x = u_w1_x + u_w2_x\n",
    "    u_w_y = u_w1_y + u_w2_y\n",
    "\n",
    "    nc.variables[\"u_w1_x\"][i_track, :] = u_w1_x\n",
    "    nc.variables[\"u_w1_y\"][i_track, :] = u_w1_y\n",
    "    nc.variables[\"u_w2_x\"][i_track, :] = u_w2_x\n",
    "    nc.variables[\"u_w2_y\"][i_track, :] = u_w2_y\n",
    "    nc.variables[\"u_w_x\"][i_track, :] = u_w_x\n",
    "    nc.variables[\"u_w_y\"][i_track, :] = u_w_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a388c259-de23-4c41-9e29-904622a085f0",
   "metadata": {},
   "source": [
    "## Close parametric model netCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48369a40-0f89-4d05-afb8-8e9bdaa051fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc52997-ce24-455e-9fe7-c0425eb43202",
   "metadata": {},
   "source": [
    "## Plot for checking parametric model\n",
    "### Open parametric model netCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99298f7f-8334-4141-9986-395ad0e3a969",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncfile = \"parametric_model.nc\"\n",
    "nc = netCDF4.Dataset(ncfile, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a75fd2-b853-4160-9a79-9a5d4693db03",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_track = 120\n",
    "sp = nc.variables[\"air_pressure\"][i_track,:]\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111)\n",
    "tp = ax.tripcolor(lon, lat, nv, sp, cmap='viridis', shading='flat')\n",
    "#str_datetime = \"day=\" + str(time[num_tracks-1])\n",
    "str_datetime = \"day=\" + str(num2date(nc['time'][num_tracks-1], units=nc['time'].units, calendar=nc['time'].calendar))\n",
    "ax.text(0.05, 0.95, str_datetime, transform=ax.transAxes)\n",
    "div = make_axes_locatable(ax)\n",
    "cax = div.append_axes(\"right\", size=\"5%\", pad=0.2)\n",
    "cb = fig.colorbar(tp, cax=cax)\n",
    "cb.set_label(\"Atmospheric pressure (hPa)\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e302cecc-d978-4429-aa71-eb04c7aca9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set plot parameters\n",
    "i_track = 120\n",
    "sp = nc.variables[\"air_pressure\"][i_track,:]\n",
    "u_w1_x = nc.variables[\"u_w1_x\"][i_track,:]\n",
    "u_w1_y = nc.variables[\"u_w1_y\"][i_track,:]\n",
    "u_w2_x = nc.variables[\"u_w2_x\"][i_track,:]\n",
    "u_w2_y = nc.variables[\"u_w2_y\"][i_track,:]\n",
    "u_w_x = nc.variables[\"u_w_x\"][i_track,:]\n",
    "u_w_y = nc.variables[\"u_w_y\"][i_track,:]\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111)\n",
    "u_w1_scale = np.sqrt(np.square(u_w1_x) + np.square(u_w1_y))\n",
    "#vel_scale = u_w1_scale\n",
    "#u_w2_scale = np.sqrt(np.square(u_w2_x) + np.square(u_w2_y))\n",
    "#vel_scale = u_w2_scale\n",
    "#u_w_scale = np.sqrt(np.square(u_w_x) + np.square(u_w_y))\n",
    "#vel_scale = u_w_scale\n",
    "\n",
    "vel_scale = 10\n",
    "vel_scale = np.where(vel_scale > 0.1, vel_scale, 0.1)\n",
    "\n",
    "ax.quiver(lonc, latc, u_w1_x/vel_scale, u_w1_y/vel_scale, cmap='jet', scale=100)\n",
    "#ax.quiver(lonc, latc, u_w2_x/vel_scale, u_w2_y/vel_scale, cmap='jet', scale=100)\n",
    "#ax.quiver(lonc, latc, u_w_x/vel_scale, u_w_y/vel_scale, cmap='jet', scale=100)\n",
    "\n",
    "str_datetime = \"day=\" + str(num2date(nc['time'][i_track], units=nc['time'].units, calendar=nc['time'].calendar))\n",
    "ax.text(0.05, 0.95, str_datetime, transform=ax.transAxes)  ## Put text relative to the axis frame\n",
    "\n",
    "ax.set_xlim(137,142)\n",
    "ax.set_ylim(18, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0530652c-7605-40f7-a5b3-f587cfed0f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "## Plot atmospheric pressure field\n",
    "tp = ax.tripcolor(lon, lat, nv, sp, cmap='viridis', shading='flat')\n",
    "str_datetime = \"day=\" + str(num2date(nc['time'][num_tracks-1], units=nc['time'].units, calendar=nc['time'].calendar))\n",
    "#str_datetime = \"day=\" + str(nc['time'][num_tracks-1])\n",
    "ax.text(0.05, 0.95, str_datetime, transform=ax.transAxes)  ## Put text relative to the axis frame\n",
    "div = make_axes_locatable(ax)\n",
    "cax = div.append_axes(\"right\", size=\"5%\", pad=0.2)\n",
    "cb = fig.colorbar(tp, cax=cax)\n",
    "cb.set_label(\"Atmospheric pressure (hPa)\", fontsize=20)\n",
    "\n",
    "## Plot vectors\n",
    "u_w1_scale = np.sqrt(np.square(u_w1_x) + np.square(u_w1_y))\n",
    "vel_scale = 10\n",
    "vel_scale = np.where(vel_scale > 0.1, vel_scale, 0.1)\n",
    "ax.quiver(lonc, latc, u_w1_x/vel_scale, u_w1_y/vel_scale, scale=100)\n",
    "\n",
    "ax.set_xlim(137,142)\n",
    "ax.set_ylim(18, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cc1fbd-7770-4c4a-8b81-bbd6c25e79cb",
   "metadata": {},
   "source": [
    "## Grid layout plot ([reference](https://www.yutaka-note.com/entry/matplotlib_subplots))\n",
    "### Using `plt.subplots` but difficult in fine adjustment\n",
    "- `squeeze=False`: The shape of axes is kept 2D even for the cases of one row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71cd111-05d3-449d-85ad-62af2c327737",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "nrows=1\n",
    "ncols=3\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(18,6), squeeze=False, \n",
    "                         sharey=\"all\")\n",
    "str_datetime = \"day=\" + str(time[num_tracks-1])\n",
    "u_w1_scale = np.sqrt(np.square(u_w1_x) + np.square(u_w1_y))\n",
    "vel_scale = 10\n",
    "vel_scale = np.where(vel_scale > 0.1, vel_scale, 0.1)\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "        ## Plot atmospheric pressure field\n",
    "        tp = axes[i,j].tripcolor(lon, lat, nv, sp, cmap='viridis', shading='flat')\n",
    "        axes[i,j].text(0.05, 0.95, str_datetime, transform=axes[i,j].transAxes)  ## Put text relative to the axis frame\n",
    "        axes[i,j].axis('equal')\n",
    "        axes[i,j].set_xlim(137,142)\n",
    "        axes[i,j].set_ylim(18, 25)\n",
    "        ## PLot vector field\n",
    "        axes[i,j].quiver(lonc, latc, u_w1_x/vel_scale, u_w1_y/vel_scale, scale=100)\n",
    "cb = fig.colorbar(tp, ax=axes.flat)\n",
    "cb.set_label(\"Atmospheric pressure (hPa)\", fontsize=20)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1a33b8-8c8f-4d73-8212-b057ea0bbc46",
   "metadata": {},
   "source": [
    "### Using ImageGrid (recommended) [Ref 1](https://sabopy.com/py/matplotlib-19/), [Ref 2](https://sabopy.com/py/matplotlib-20/), [Official ref](https://matplotlib.org/stable/api/_as_gen/mpl_toolkits.axes_grid1.axes_grid.ImageGrid.html#mpl_toolkits.axes_grid1.axes_grid.ImageGrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef49cbb-39c3-4fdd-b96e-3a86fc3cd11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare for vector field plot\n",
    "vel_scale = 0.8\n",
    "vel_scale = np.where(vel_scale > 0.1, vel_scale, 0.1)\n",
    "u_plot=[]; v_plot=[]\n",
    "u_plot.append(u_w1_x); v_plot.append(u_w1_y) ## circular wind vector field deflected by 30 degrees anticlockwise\n",
    "u_plot.append(u_w2_x); v_plot.append(u_w2_y) ## translation wind field\n",
    "u_plot.append(u_w_x) ; v_plot.append(u_w_y)  ## final wind vector field\n",
    "## Prepare for text of date\n",
    "#str_datetime = \"day=\" + str(nc['time'][num_tracks-1])\n",
    "str_datetime = \"day=\" + str(num2date(nc['time'][num_tracks-1], units=nc['time'].units, calendar=nc['time'].calendar))\n",
    "\n",
    "## Start plotting\n",
    "fig = plt.figure(figsize=(18,6))\n",
    "grid = ImageGrid(fig, 111, nrows_ncols=(1,3), axes_pad=0.25, share_all=True, aspect=True,\n",
    "                 cbar_location=\"right\", cbar_mode=\"single\", cbar_size=\"5%\", cbar_pad=0.2)\n",
    "## Add data to image grid\n",
    "for i, ax in enumerate(grid):\n",
    "    ## Plot atmospheric pressure field\n",
    "    tp = ax.tripcolor(lon, lat, nv, sp, cmap='viridis', shading='flat')\n",
    "    ax.text(0.05, 0.95, str_datetime, transform=ax.transAxes)  ## Put text relative to the axis frame\n",
    "    ax.set_xlim(137,142)\n",
    "    ax.set_ylim(18, 25)\n",
    "    ## PLot vector field\n",
    "    #ax.quiver(lonc, latc, u_w1_x/vel_scale, u_w1_y/vel_scale, scale=100)\n",
    "    ax.quiver(lonc, latc, u_plot[i]/vel_scale, v_plot[i]/vel_scale, scale=100)\n",
    "## Add colorbar\n",
    "cb=ax.cax.colorbar(tp)\n",
    "cb.set_label(\"Atmospheric pressure (hPa)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbf7950-ed3e-4679-a199-f1f30883c3f4",
   "metadata": {},
   "source": [
    "## Close parametric model netCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ab6840-7149-4e56-bfb1-ab80932979fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c9d911-9a8f-4c91-889e-3b7a8ff73ec0",
   "metadata": {},
   "source": [
    "# Create ERA netCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9c842e-cc0e-4dc8-9cdf-608b51364200",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncfile = \"era_model.nc\"\n",
    "nc = netcdf_storm(ncfile, x, y, lon, lat, xc, yc, lonc, latc, nv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa488afa-d572-44c9-9127-e00201afa6f8",
   "metadata": {},
   "source": [
    "## Read ERA data\n",
    "- `sp(time, latitude, longitude)`: surface pressure (Pa)\n",
    "- `time`: hours since 1900-01-01 00:00:00.0 (standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874aafa7-6089-402c-937f-4fee4ad64ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read ERA wind\n",
    "era_uv_nc = \"era5_10u10v_201910041014.nc\"\n",
    "ERA_uv = netCDF4.Dataset(era_uv_nc, 'r')\n",
    "#lon_era_uv = np.ma.filled(ERA_uv.variables['longitude'][:])\n",
    "#lat_era_uv = np.ma.filled(ERA_uv.variables['latitude'][:])\n",
    "#time_era_uv = np.ma.filled(ERA_uv.variables['time'][:])\n",
    "#u_era = np.ma.filled(ERA_uv.variables['u10'][:])\n",
    "#v_era = np.ma.filled(ERA_uv.variables['v10'][:])\n",
    "lon_era_uv = ERA_uv.variables['longitude'][:]\n",
    "lat_era_uv = ERA_uv.variables['latitude'][:]\n",
    "time_era_uv = ERA_uv.variables['time'][:]\n",
    "u_era = ERA_uv.variables['u10'][:]\n",
    "v_era = ERA_uv.variables['v10'][:]\n",
    "\n",
    "\n",
    "num_lon_era_uv = lon_era_uv.size\n",
    "num_lat_era_uv = lat_era_uv.size\n",
    "num_time_era_uv = time_era_uv.size\n",
    "\n",
    "## Read ERA sea surface pressure\n",
    "era_sp_nc = \"era5_sp_201910041014.nc\"\n",
    "ERA_sp = netCDF4.Dataset(era_sp_nc, 'r')\n",
    "#lon_era_sp = np.ma.filled(ERA_sp.variables['longitude'][:])\n",
    "#lat_era_sp = np.ma.filled(ERA_sp.variables['latitude'][:])\n",
    "#time_era_sp = np.ma.filled(ERA_sp.variables['time'][:])\n",
    "#sp_era = np.ma.filled(ERA_sp.variables['sp'][:])\n",
    "lon_era_sp = ERA_sp.variables['longitude'][:]\n",
    "lat_era_sp = ERA_sp.variables['latitude'][:]\n",
    "time_era_sp = ERA_sp.variables['time'][:]\n",
    "sp_era = ERA_sp.variables['sp'][:]\n",
    "\n",
    "num_lon_era_sp = lon_era_sp.size\n",
    "num_lat_era_sp = lat_era_sp.size\n",
    "num_time_era_sp = time_era_sp.size\n",
    "\n",
    "## Check whether both times are identical, or raise an error.\n",
    "if np.all(time_era_uv == time_era_sp):\n",
    "    print(\"time_era_uv == time_era_sp; use time_era\")\n",
    "    time_era = time_era_uv\n",
    "    time_era_units = ERA_sp.variables['time'].units\n",
    "    time_era_calendar = ERA_sp.variables['time'].calendar\n",
    "    print(time_era_units)\n",
    "    print(time_era_calendar)\n",
    "else:\n",
    "    raise ValueError(\"ERROR: time_era /= time_era_uv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551c4a0c-169f-4f0f-acb6-c7ff769c3d3a",
   "metadata": {},
   "source": [
    "### Find a ERA grid point `(i,j)` where the grid area between `(i,j)` and `(i+1,j+1)` contains an FVCOM node or cell center\n",
    "lon_era ranges from small to large numbers while lat_era ranges from large to small numbers.\n",
    "```\n",
    "    i       i+1    *: FVCOM grid node or cell center index n\n",
    "j   |--------|     i: Longitude grid index of ERA   \n",
    "    |  * n   |     j: Latitude grid indes of ERA (positive downward)\n",
    "j+1 |--------|\n",
    "```\n",
    "### Interpolate ERA surface pressure at FVCOM node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d28b0c3-8294-49af-87f0-6f23ed613f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dlon_era_uv = lon_era_uv[1] - lon_era_uv[0]\n",
    "#dlat_era_uv = lat_era_uv[0] - lat_era_uv[1]\n",
    "dlon_era_sp = lon_era_sp[1] - lon_era_sp[0]\n",
    "dlat_era_sp = lat_era_sp[0] - lat_era_sp[1]\n",
    "i_sp = (np.trunc((lon - lon_era_sp[0]) / dlon_era_sp)).astype(int)\n",
    "j_sp = (np.trunc((lat_era_sp[0] - lat) / dlat_era_sp)).astype(int)\n",
    "#print(lat_era_sp[0])\n",
    "#print(lat)\n",
    "#print(j_sp)\n",
    "#print(lat[0])\n",
    "#print(lat_era_sp[j_sp[0]], lat_era_sp[j_sp[0]+1])\n",
    "cx0 = (lon - lon_era_sp[i_sp]) / (lon_era_sp[i_sp+1] - lon_era_sp[i_sp])\n",
    "cx1 = (lon_era_sp[i_sp + 1] - lon) / (lon_era_sp[i_sp + 1] - lon_era_sp[i_sp])\n",
    "cy0 = (lat_era_sp[j_sp] - lat) / (lat_era_sp[j_sp] - lat_era_sp[j_sp + 1])\n",
    "cy1 = (lat - lat_era_sp[j_sp + 1]) / (lat_era_sp[j_sp] - lat_era_sp[j_sp + 1])\n",
    "#print(cy0 + cy1)\n",
    "\n",
    "#print(sp_era[0, [0, 3], [0, 2]])\n",
    "#print(sp_era[0, 0, 0])\n",
    "#print(sp_era[0, 3, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2786a27-a7ac-4e00-b5f4-61391157e4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_era = num2date(time_era, units=time_era_units, calendar=time_era_calendar)\n",
    "days_era = date2num(dates_era, units=\"days since 1858-11-17 00:00:00\", calendar=\"gregorian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e109b5-15ec-41e0-b991-940c93eff5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Interpolation\n",
    "#print(cy0.shape)\n",
    "#print(cy1.shape)\n",
    "#print(sp_era_fvcom_j0.shape)\n",
    "#print(sp_era_fvcom_j1.shape)\n",
    "## ERAの時間とFVCOMの時間を合わせ，netCDFはFVCOMの時間で作る\n",
    "## Matching ERA time and FVCOM time; creating netCDF time using FVCOM time\n",
    "for time in np.arange(time_era.size):\n",
    "    sp_era_fvcom_j0 = cx1 * sp_era[time, j_sp, i_sp] + cx0 * sp_era[time, j_sp, i_sp+1]\n",
    "    #print(sp_era_fvcom_j0.shape)\n",
    "    sp_era_fvcom_j1 = cx1 * sp_era[time, j_sp+1, i_sp] + cx0 * sp_era[time, j_sp+1, i_sp+1]\n",
    "    #print(sp_era_fvcom_j1.shape)\n",
    "    sp_era_fvcom = cy1 * sp_era_fvcom_j0 + cy0 * sp_era_fvcom_j1\n",
    "    #print(sp_era_fvcom.shape)\n",
    "    nc.variables[\"time\"][time] = days_era[time]\n",
    "    nc.variables[\"air_pressure\"][time, :] = sp_era_fvcom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf082fb-907c-4951-a704-818f42c9e83a",
   "metadata": {},
   "source": [
    "### Interpolate ERA wind field at FVCOM cell center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dfad82-a3ae-4363-a595-66dcac24d8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dlon_era_uv = lon_era_uv[1] - lon_era_uv[0]\n",
    "dlat_era_uv = lat_era_uv[0] - lat_era_uv[1]\n",
    "i_uv = (np.trunc((lonc - lon_era_uv[0]) / dlon_era_uv)).astype(int)\n",
    "j_uv = (np.trunc((lat_era_uv[0] - latc) / dlat_era_uv)).astype(int)\n",
    "cx0 = (lonc - lon_era_uv[i_uv]) / (lon_era_uv[i_uv+1] - lon_era_uv[i_uv])\n",
    "cx1 = (lon_era_uv[i_uv + 1] - lonc) / (lon_era_uv[i_uv + 1] - lon_era_uv[i_uv])\n",
    "cy0 = (lat_era_uv[j_uv] - latc) / (lat_era_uv[j_uv] - lat_era_uv[j_uv + 1])\n",
    "cy1 = (latc - lat_era_uv[j_uv + 1]) / (lat_era_uv[j_uv] - lat_era_uv[j_uv + 1])\n",
    "                                                                      \n",
    "for time in np.arange(time_era.size):\n",
    "    u_era_fvcom_j0 = cx1 * u_era[time, j_uv, i_uv] + cx0 * u_era[time, j_uv, i_uv+1]\n",
    "    #print(sp_era_fvcom_j0.shape)\n",
    "    u_era_fvcom_j1 = cx1 * u_era[time, j_uv+1, i_uv] + cx0 * u_era[time, j_uv+1, i_uv+1]\n",
    "    #print(sp_era_fvcom_j1.shape)\n",
    "    u_era_fvcom = cy1 * u_era_fvcom_j0 + cy0 * u_era_fvcom_j1\n",
    "    #print(sp_era_fvcom.shape)\n",
    "    nc.variables[\"u_w_x\"][time, :] = u_era_fvcom\n",
    "\n",
    "    v_era_fvcom_j0 = cx1 * v_era[time, j_uv, i_uv] + cx0 * v_era[time, j_uv, i_uv+1]\n",
    "    v_era_fvcom_j1 = cx1 * v_era[time, j_uv+1, i_uv] + cx0 * v_era[time, j_uv+1, i_uv+1]\n",
    "    v_era_fvcom = cy1 * v_era_fvcom_j0 + cy0 * v_era_fvcom_j1\n",
    "    nc.variables[\"u_w_y\"][time, :] = v_era_fvcom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71fb7bf-39cb-483a-9e5b-4cb1eca5e0fe",
   "metadata": {},
   "source": [
    "## Close ERA netCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69749782-8b5c-434f-b29f-942a9ec927ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cccc471-b7d9-4c76-b04b-246ec93c57eb",
   "metadata": {},
   "source": [
    "## Plot for checking ERA\n",
    "### Open ERA netCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92db064b-b37e-439b-aefb-38f9f8be10d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncfile = \"era_model.nc\"\n",
    "nc = netCDF4.Dataset(ncfile, \"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9fe2b0-eb77-4ceb-8bd8-af7783f3d99e",
   "metadata": {},
   "source": [
    "### Plot ERA surface pressure field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d0c0d7-62a3-4d9b-8e01-5ea64fcb2fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep = 180\n",
    "sp = nc.variables[\"air_pressure\"][timestep,:]\n",
    "u_w_x = nc.variables[\"u_w_x\"][timestep,:]\n",
    "u_w_y = nc.variables[\"u_w_y\"][timestep,:]\n",
    "str_datetime = \"day=\" + str(dates_era[timestep])\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "## Plot atmospheric pressure field\n",
    "tp = ax.tripcolor(lon, lat, nv, sp/100, cmap='viridis', shading='flat')\n",
    "ax.text(0.05, 0.95, str_datetime, transform=ax.transAxes)  ## Put text relative to the axis frame\n",
    "div = make_axes_locatable(ax)\n",
    "cax = div.append_axes(\"right\", size=\"5%\", pad=0.2)\n",
    "cb = fig.colorbar(tp, cax=cax)\n",
    "cb.set_label(\"Atmospheric pressure (hPa)\", fontsize=20)\n",
    "\n",
    "#ax.set_xlim(137,142)\n",
    "#ax.set_ylim(18, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf04181a-6bff-4546-be11-b5592b192d46",
   "metadata": {},
   "source": [
    "### Plot ERA wind and surface pressure field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dae212-a2d9-4828-bdfc-ca09cf74c146",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep = 180\n",
    "sp = nc.variables[\"air_pressure\"][timestep,:]\n",
    "u_w_x = nc.variables[\"u_w_x\"][timestep,:]\n",
    "u_w_y = nc.variables[\"u_w_y\"][timestep,:]\n",
    "str_datetime = \"day=\" + str(dates_era[timestep])\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "## Plot surface pressure\n",
    "tp = ax.tripcolor(lon, lat, nv, sp/100, cmap='viridis', shading='flat')\n",
    "ax.text(0.05, 0.95, str_datetime, transform=ax.transAxes)  ## Put text relative to the axis frame\n",
    "div = make_axes_locatable(ax)\n",
    "cax = div.append_axes(\"right\", size=\"5%\", pad=0.2)\n",
    "cb = fig.colorbar(tp, cax=cax)\n",
    "cb.set_label(\"Atmospheric pressure (hPa)\", fontsize=20)\n",
    "\n",
    "## Plot vectors\n",
    "## Uniform arrow length\n",
    "vel_scale = 0.5 * np.sqrt(np.square(u_w_x) + np.square(u_w_y))\n",
    "vel_scale = np.where(vel_scale > 0.1, vel_scale, 0.1)  ## Avoid divided by zero\n",
    "## Proportional arrow lenght to speed\n",
    "#vel_scale = 12\n",
    "ax.quiver(lonc, latc, u_w_x/vel_scale, u_w_y/vel_scale, scale=100)\n",
    "\n",
    "ax.set_xlim(132,142)\n",
    "ax.set_ylim(25, 35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02a6f70-1dff-4ce3-abab-e5de2fd6a438",
   "metadata": {},
   "source": [
    "## Close ERA netCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25a4dd6-6237-426c-8a2d-b5f9fc7efe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4e5f1f-fc10-42fe-9c22-191a1e068dfa",
   "metadata": {},
   "source": [
    "# Create hybrid netCDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae45f635-0f78-41e3-828f-975587f45e4d",
   "metadata": {},
   "source": [
    "## Open parametric model netCDF and ERA netCDF\n",
    "- Extract the start (`ids`) and end (`ide`) indices of the common time range for PRM (parametric) and ERA\n",
    "- Extract the same time range (from `datetime_s` to `datetime_e`) for besttrack DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b4cc44-9a25-46bb-8064-ab9d7c14a611",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create hybrid netCDF\n",
    "nc = netcdf_storm('hybrid_model.nc', x, y, lon, lat, xc, yc, lonc, latc, nv)\n",
    "\n",
    "PRM = netCDF4.Dataset(\"parametric_model.nc\", \"r\")\n",
    "ERA = netCDF4.Dataset(\"era_model.nc\", \"r\")\n",
    "time_PRM = PRM.variables[\"time\"]\n",
    "time_ERA = ERA.variables[\"time\"]\n",
    "# print(num2date(time_PRM[:], units=time_PRM.units, calendar=time_PRM.calendar))\n",
    "# print(num2date(time_ERA[:], units=time_ERA.units, calendar=time_ERA.calendar))\n",
    "day_s, day_e = max(time_PRM[0], time_ERA[0]).item(), min(time_PRM[-1], time_ERA[-1]).item()\n",
    "print(day_s, day_e)\n",
    "ids_PRM, ide_PRM = np.where(time_PRM[:] == day_s)[0].item(), np.where(time_PRM[:] == day_e)[0].item()\n",
    "print(ids_PRM, ide_PRM)\n",
    "ids_ERA, ide_ERA = np.where(time_ERA[:] == day_s)[0].item(), np.where(time_ERA[:] == day_e)[0].item()\n",
    "print(ids_ERA, ide_ERA)\n",
    "datetime_s = str(num2date(time_PRM[ids_PRM], units=time_PRM.units, calendar=time_PRM.calendar))\n",
    "datetime_e = str(num2date(time_PRM[ide_PRM], units=time_PRM.units, calendar=time_PRM.calendar))\n",
    "# print(datetime_s, datetime_e)\n",
    "# df.loc[datetime_s : datetime_e]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df1cedf-1217-4949-b031-2475297eb755",
   "metadata": {},
   "source": [
    "### Set inner (`r_i`) and outer (`r_o`) radii and band width (`b_w = r_o - r_i`) in meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51a6b48-948e-43a7-9bd8-047463332247",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_i = 300000; r_o = 500000; b_w = r_o - r_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2a6908-b4e0-4cb1-b288-2366b4a88e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = -1\n",
    "for n_PRM in np.arange(ide_PRM-ids_PRM+1):\n",
    "    n += 1\n",
    "    ## Gets ERA time index (n_ERA) corresponding to 0-indexed PRM's n\n",
    "    n_ERA = n_PRM + ids_ERA - ids_PRM\n",
    "    datetime_BST = str(num2date(time_PRM[n_PRM], units=time_PRM.units, calendar=time_PRM.calendar))\n",
    "    xt_c = df.loc[datetime_BST, 'XUTM']  ## x (UTM) of typhoon center\n",
    "    yt_c = df.loc[datetime_BST, 'YUTM']  ## y (UTM) of typhoon center\n",
    "    dist_sp = np.sqrt(np.square(x  - xt_c) + np.square(y  - yt_c))\n",
    "    dist_uv = np.sqrt(np.square(xc - xt_c) + np.square(yc - yt_c))\n",
    "\n",
    "    sp = ERA['air_pressure'][n_ERA, :]\n",
    "    sp = np.where(dist_sp <= r_i, PRM['air_pressure'][n_PRM, :], sp)\n",
    "    ## dist_sp = dist_sp when FVCOM node is in the region between inner and outer circles, otherwise = np.nan\n",
    "    dist_sp = np.where((dist_sp > r_i) & (dist_sp < r_o), dist_sp, np.nan)  ## dist_sp between inner and outer circles\n",
    "    dr_i = dist_sp - r_i  ## distance between FVCOM True node and inner circle\n",
    "    dr_o = r_o - dist_sp  ## distance between FVCOM True node and outer circle\n",
    "    sp = np.where(~np.isnan(dist_sp), dr_i/b_w * ERA['air_pressure'][n_ERA,:]\n",
    "                  + dr_o/b_w * PRM['air_pressure'][n_PRM,:], sp)\n",
    "\n",
    "    nc.variables[\"time\"][n] = PRM[\"time\"][n_PRM]\n",
    "    nc.variables[\"air_pressure\"][n, :] = sp\n",
    "\n",
    "    u_w_x = ERA['u_w_x'][n_ERA, :]\n",
    "    u_w_y = ERA['u_w_y'][n_ERA, :]\n",
    "    u_w_x = np.where(dist_uv <= r_i, PRM['u_w_x'][n_PRM, :], u_w_x)\n",
    "    u_w_y = np.where(dist_uv <= r_i, PRM['u_w_y'][n_PRM, :], u_w_y)\n",
    "    ## dist_uv = dist_uv when FVCOM nele is in the region between inner and outer circles, otherwise = np.nan\n",
    "    dist_uv = np.where((dist_uv > r_i) & (dist_uv < r_o), dist_uv, np.nan)  ## dist_uv between inner and outer circles\n",
    "    dr_i = dist_uv - r_i  ## distance between FVCOM True nele and inner circle\n",
    "    dr_o = r_o - dist_uv  ## distance between FVCOM True nele and outer circle\n",
    "    u_w_x = np.where(~np.isnan(dist_uv), dr_i/b_w * ERA['u_w_x'][n_ERA,:] + dr_o/b_w * PRM['u_w_x'][n_PRM,:], u_w_x)\n",
    "    u_w_y = np.where(~np.isnan(dist_uv), dr_i/b_w * ERA['u_w_y'][n_ERA,:] + dr_o/b_w * PRM['u_w_y'][n_PRM,:], u_w_y)\n",
    "    nc.variables[\"u_w_x\"][n, :] = u_w_x\n",
    "    nc.variables[\"u_w_y\"][n, :] = u_w_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7270aa-908d-4d5d-a0d4-13460f8def8f",
   "metadata": {},
   "source": [
    "## Close hybrid netCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59208654-77f1-400c-bf92-da5fafabb320",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRM.close()\n",
    "ERA.close()\n",
    "nc.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508d4d4d-3e6d-44bd-a8f7-67d5b50cc34c",
   "metadata": {},
   "source": [
    "# Plot for checking hybrid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a2630b-72df-4785-a49c-2234fe85b060",
   "metadata": {},
   "source": [
    "# Create FVCOM input netCDF\n",
    "## Open storm model netCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2985c0-ae1a-4283-8566-fe77c8e3fe18",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncifile = 'parametric_model.nc'\n",
    "#ncifile = 'era_model.nc'\n",
    "#ncifile = 'hybrid_model.nc'\n",
    "nci = netCDF4.Dataset(ncifile, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad06626f-7eba-4fc5-9965-07df4868ee76",
   "metadata": {},
   "outputs": [],
   "source": [
    "nele = nci.dimensions['nele'].size\n",
    "node = nci.dimensions['node'].size\n",
    "x = nci['x'][:]\n",
    "y = nci['y'][:]\n",
    "lon = nci['lon'][:]\n",
    "lat = nci['lat'][:]\n",
    "xc = nci['xc'][:]\n",
    "yc = nci['yc'][:]\n",
    "lonc = nci['lonc'][:]\n",
    "latc = nci['latc'][:]\n",
    "uwind_speed = nci['u_w_x'][:]\n",
    "vwind_speed = nci['u_w_y'][:]\n",
    "air_pressure = nci['air_pressure'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db4ccb6-2937-44bc-8f4a-e90670ca416e",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_attributes = nci.__dict__  ## global attribute {name: value} pairs in a dictionary\n",
    "times = num2date(nci['time'][:], units=nci['time'].units, calendar=nci['time'].calendar)\n",
    "#times = np.ma.filled(times, np.nan)\n",
    "#times = [str(time) for time in times]\n",
    "#times = [time.strftime() for time in times]\n",
    "Times = [parse(time.strftime()) for time in times]\n",
    "#print(Times)\n",
    "#Times[0].strftime('%Y-%m-%dT%H:%M:%S.%f')\n",
    "#print(times[0].strftime('%Y-%m-%d %H:%M:%S.%f'))\n",
    "#print(times[0].strftime('%Y-%m-%dT%H:%M:%S'))\n",
    "#print(times[0].strftime())\n",
    "#print(uwind_speed.shape)\n",
    "#print(times.shape)\n",
    "#print(latc.shape)\n",
    "#date2num(Times, units='days since 1858-11-17 00:00:00')\n",
    "nci.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cde44c-d087-472c-8aa4-cc59d0fefc86",
   "metadata": {},
   "source": [
    "## Open and define FVCOM input netCDF\n",
    "- `add_varialbe(self, name, data, dimensions, attributes, format, ncopts={})`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f894583-51a4-4ce3-baa7-5976a00c2455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_fvcom_forcing(ncfile, nele, node, global_attributes, nv, Times, x, y, lon, lat, xc, yc, lonc, latc,\n",
    "                        uwind_speed, vwind_speed, air_pressure):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    dimensions = {'nele': nele, 'node': node, 'three': 3, 'time': None, 'DateStrLen': 26}\n",
    "    with pf.preproc.WriteForcing(filename=ncfile, dimensions=dimensions, global_attributes=global_attributes,\n",
    "                                 format='NETCDF4') as nc:\n",
    "        nc.write_fvcom_time(time=Times)\n",
    "        nc.add_variable('x', x, ('node',), {'long_name': 'nodal x-coordinate', 'units': 'meters'})\n",
    "        nc.add_variable('y', y, ('node',), {'long_name': 'nodal y-coordinate', 'units': 'meters'})\n",
    "        nc.add_variable('lon', lon, ('node',), {'long_name': 'nodal longitude', 'standard_name': 'longitude', \\\n",
    "                                                'units': 'degrees_east'})\n",
    "        nc.add_variable('lat', lat, ('node',), {'long_name': 'nodal latitude', 'standard_name': 'latitude', \\\n",
    "                                                'units': 'degrees_north'})\n",
    "        nc.add_variable('xc', xc, ('nele',), {'long_name': 'zonal x-coordinate', 'units': 'meters'})\n",
    "        nc.add_variable('yc', yc, ('nele',), {'long_name': 'zonal y-coordinate', 'units': 'meters'})\n",
    "        nc.add_variable('lonc', lonc, ('nele',), {'long_name': 'zonal longitude', 'standard_name': 'longitude', \\\n",
    "                                                  'units': 'degrees_east'})\n",
    "        nc.add_variable('latc', latc, ('nele',), {'long_name': 'zonal latitude', 'standard_name': 'latitude', \\\n",
    "                                                  'units': 'degrees_north'})\n",
    "        nc.add_variable('nv', nv.T, ('three', 'nele',), {'long_name': 'nodes surrounding element'}, 'i')\n",
    "\n",
    "        nc.add_variable('uwind_speed', uwind_speed, ('time', 'nele',), {'long_name': 'Eastward Wind Speed', \\\n",
    "                        'standard_name': 'Wind Speed', 'units': 'm/s', 'grid': 'fvcom_grid', 'type': 'data'})\n",
    "        nc.add_variable('vwind_speed', vwind_speed, ('time', 'nele',), {'long_name': 'Northward Wind Speed', \\\n",
    "                        'standard_name': 'Wind Speed', 'units': 'm/s', 'grid': 'fvcom_grid', 'type': 'data'})\n",
    "        nc.add_variable('air_pressure', air_pressure, ('time', 'node',), {'long_name': 'surface air pressure', \\\n",
    "                        'units': 'Pa', 'grid': 'fvcom_grid', 'coordinates': 'FVCOM Cartesian coordinates', 'type': 'data'})\n",
    "\n",
    "write_fvcom_forcing(fvcom_wnd, nele, node, global_attributes, nv, Times, x, y, lon, lat, xc, yc, lonc, latc, \n",
    "                    uwind_speed, vwind_speed, air_pressure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e1c8ea-cd1c-49f0-804e-b4e260f7545b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = netCDF4.Dataset(fvcom_wnd, \"r\")\n",
    "nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c63143-1b26-4a70-9f72-b84aacae8922",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac722b4a-330a-4739-99d8-aba0b59dbe5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
